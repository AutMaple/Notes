# 集合概述

Java 集合， 也叫作容器，主要是由两大接口派生而来：一个是 `Collection`接口，主要用于存放单一元素；另一个是 `Map` 接口，主要用于存放键值对。对于`Collection` 接口，下面又有三个主要的子接口：`List`、`Set` 和 `Queue`。

Java 集合框架如下图所示：

![img](https://javaguide.cn/assets/java-collection-hierarchy.1727461b.png)

## Collection 和 List 的区别

1. Collection 和 List 最大的区别就是 Collection 是无序的，不支持索引操作，而 List 是有序的。Collection 没有顺序的概念。
2. 由于 List 是有序的，因此 List 接口中存在 sort 方法

### 为什么子类接口里重复申明父类接口呢?

官方解释: 在子接口中重复声明父接口是为了方便看文档。比如在 java doc 文档里，在 List 接口里也能看到 Collecion 声明的相关接口。

## List, Queue, Set, Map 的特点

- List： 存储的元素是有序且可重复的。
- Queue：按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。
- Set: 存储的元素是无序不可重复的
- Map：存储键值对，key 是无序不可重复的，value 是无序可重复的。每个 key 最多映射到一个值

所谓的有序指的是存放的顺序和取出的顺序是一致的。

## Arraylist 与 LinkedList 区别?

1. **是否保证线程安全：** `ArrayList` 和 `LinkedList` 都是不同步的，也就是不保证线程安全；
2. **底层数据结构：** `Arraylist` 底层使用的是 **`Object` 数组**；`LinkedList` 底层使用的是 **双向链表** 数据结构（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别，下面有介绍到！）
3. 插入和删除是否受元素位置的影响：
   - `ArrayList` 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 比如：执行`add(E e)`方法的时候， `ArrayList` 会默认在将指定的元素追加到此列表的末尾，这种情况时间复杂度就是 O(1)。但是如果要在指定位置 i 插入和删除元素的话（`add(int index, E element)`）时间复杂度就为 O(n-i)。因为在进行上述操作的时候集合中第 i 和第 i 个元素之后的(n-i)个元素都要执行向后位/向前移一位的操作。
   - `LinkedList` 采用链表存储，所以，如果是在头尾插入或者删除元素不受元素位置的影响（`add(E e)`、`addFirst(E e)`、`addLast(E e)`、`removeFirst()` 、 `removeLast()`），近似 O(1)，如果是要在指定位置 `i` 插入和删除元素的话（`add(int index, E element)`，`remove(Object o)`） 时间复杂度近似为 O(n) ，因为需要先移动到指定位置再插入。
4. **是否支持快速随机访问：** `LinkedList` 不支持高效的随机元素访问，而 `ArrayList` 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于`get(int index)`方法)。
5. **内存空间占用：** ArrayList 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数据）。

## ArrayList 的扩容机制

### 定义的常量

```java
public class ArrayList<E> extends AbstractList<E> implements List<E>, RandomAccess, Cloneable, Serializable {
   

    //默认初始化容量
    private static final int DEFAULT_CAPACITY = 10;

    //默认的空的数组，这个主要是在构造方法初始化一个空数组的时候使用
    private static final Object[] EMPTY_ELEMENTDATA = {};

    //使用默认size大小的空数组实例，和 EMPTY_ELEMENTDATA 区分开来，
    //这样可以知道当第一个元素添加的时候进行扩容至多少
    private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};

    //ArrayList底层存储数据就是通过数组的形式，ArrayList长度就是数组的长度。
    //一个空的实例elementData为上面的DEFAULTCAPACITY_EMPTY_ELEMENTDATA，当添加第一个元素的时候
    //会进行扩容，扩容大小就是上面的默认容量DEFAULT_CAPACITY
    transient Object[] elementData; // non-private to simplify nested class access

    //arrayList的大小
    private int size;
    
    // 最大容量
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;


    
}
```

### 构造方法

```java
public ArrayList(int initialCapacity) {
    if (initialCapacity > 0) {
        this.elementData = new Object[initialCapacity];
    } else if (initialCapacity == 0) {
        this.elementData = EMPTY_ELEMENTDATA;
    } else {
        throw new IllegalArgumentException("Illegal Capacity: "+
                                           initialCapacity);
    }
}
public ArrayList() {
    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;
}

```

区别在于`无参构造方法会将 elementData 初始化一个空数组，插入元素时，扩容将会按默认值重新初始化数组`。而`有参的构造方法则会将 elementData 初始化为参数值大小（>= 0）的数组`

### 添加元素的方法

```java
public boolean add(E e) {
    ensureCapacityInternal(size + 1); // Increments modCount!! 里面调用：calculateCapacity()方法
    elementData[size++] = e;
    return true;
}
```

### 扩容的方法

```java

/**
 *	DEFAULTCAPACITY_EMPTY_ELEMENTDATA 与 EMPTY_ELEMENTDATA的区别是：
 *		当我们向数组中添加第一个元素时，DEFAULTCAPACITY_EMPTY_ELEMENTDATA 将会知道数组该扩充多少。
 */
// 传递的 minCapacity 如果不是使用无参构造方法创建的 ArrayList，则等于 size + 1 否则等于默认容量大小：10
private static int calculateCapacity(Object[] elementData, int minCapacity) {
    // 这里判断如果 elementData 是否是使用无参构造方法创建的数组，如果是，就将数组扩充为默认的容量 10
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        //DEFAULT_CAPACITY 是 10
        return Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    return minCapacity;
}

private void ensureExplicitCapacity(int minCapacity) {
    modCount++;

    // overflow-conscious code
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}

private void grow(int minCapacity) {
    // oldCapacity为旧数组的容量
    int oldCapacity = elementData.length;
    // newCapacity为新数组的容量（oldCap+oldCap/2:即更新为旧容量的1.5倍）
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    // 检查新容量的大小是否小于最小需要容量，如果小于那旧将最小容量最为数组的新容量
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    //如果新容量大于MAX_ARRAY_SIZE，使用hugeCapacity比较二者
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    // 将原数组中的元素拷贝
    elementData = Arrays.copyOf(elementData, newCapacity);
}

private static int hugeCapacity(int minCapacity) {
    if (minCapacity < 0) // overflow
        throw new OutOfMemoryError();
    //对minCapacity和MAX_ARRAY_SIZE进行比较
    //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小
    //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小
    //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
    return (minCapacity > MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;
}
```

### 添加元素的流程

1. 首先计算最小容量 minCapacity

   - 如果 elementData 等于无参构造方法指定的空数组，就将 minCapacity 设置为默认的容量 10 与传递的容量参数中两者的最小值；否则 minCapacity 就是传递的最小容量：size + 1；`size：当前存储的与元素个数`

2. 判断是否需要扩容
   - 如果 minCapacity 大于的 elementData 数组的长度，就进行扩容，否则不进行扩容
3. 扩容的大小为在原来的基础上加一半：即 `length = length + (length >> 1)`
4. 扩容之后将原数组中的元素拷贝过去，然后再将需要添加的元素添加进去

### ArrayList总结

（1）`ArrayList` 是一种变长的集合类，基于定长数组实现，使用默认构造方法初始化出来的容量是10（1.7之后都是延迟初始化，即第一次调用add方法添加元素的时候才将elementData容量初始化为10）。

（2）`ArrayList` 允许空值和重复元素，当往 ArrayList 中添加的元素数量大于其底层数组容量时，其会通过**扩容**机制重新生成一个更大的数组。`ArrayList`扩容的长度是原长度的 0.5 倍，即：`length = length + (length >> 1)`

（3）由于 `ArrayList` 底层基于数组实现，所以其可以保证在 `O(1)` 复杂度下完成随机查找操作。

（4）`ArrayList` 是非线程安全类，并发环境下，多个线程同时操作 ArrayList，会引发不可预知的异常或错误。

（5）顺序添加很方便

（6）Integer.MAX_VALUE - 8 ：主要是考虑到不同的 JVM ,有的JVM会在加入一些数据头,当扩容后的容量大于MAX_ARRAY_SIZE,我们会去比较最小需要容量和 MAX_ARRAY_SIZE 做比较,如果比它大, 只能取Integer.MAX_VALUE,否则是 Integer.MAX_VALUE - 8。 这个是从 jdk1.7 开始才有的

## fast fail 机制

fail-fast的解释：

> 在系统设计中，快速失效系统一种可以立即报告任何可能表明故障的情况的系统。快速失效系统通常设计用于停止正常操作，而不是试图继续可能存在缺陷的过程。这种设计通常会在操作中的多个点检查系统的状态，因此可以及早检测到任何故障。快速失败模块的职责是检测错误，然后让系统的下一个最高级别处理错误。

就是在做系统设计的时候先考虑异常情况，一旦发生异常，直接停止并上报，比如下面的这个简单的例子

```java
//这里的代码是一个对两个整数做除法的方法，在 fast_fail_method 方法中，我们对被除数做了个简单的检查，如果其值为0，那么就直接抛出一个异常，并明确提示异常原因。这其实就是fail-fast理念的实际应用。
public int fast_fail_method(int arg1,int arg2){
    if(arg2 == 0){
        throw new RuntimeException("can't be zero");
    }
    return arg1/arg2;
}
```

在 Java 集合类中很多地方都用到了该机制进行设计，一旦使用不当，触发 fail-fast 机制设计的代码，就会发生非预期情况。我们通常说的 Java 中的 fail-fast 机制，**默认指的是 Java 集合的一种错误检测机制**。当多个线程对部分集合进行结构上的改变的操作时，有可能会触发该机制时，之后就会抛出并发修改异常**`ConcurrentModificationException`**.当然如果不在多线程环境下，如果在 foreach 遍历的时候使用 `add/remove` 方法，也可能会抛出该异常。参考[fast-fail机制](https://link.juejin.cn?target=https%3A%2F%2Fwww.hollischuang.com%2Farchives%2F3542)，这里简单做个总结

之所以会抛出 ConcurrentModificationException 异常，是因为我们的代码中使用了增强 for 循环，而在增强 for 循环中，集合遍历是通过 iterator 进行的，但是元素的 add/remove 却是直接使用的集合类自己的方法。这就导致 iterator 在遍历的时候，会发现有一个元素在自己不知不觉的情况下就被删除/添加了，就会抛出一个异常，用来提示可能发生了并发修改！所以，在使用 Java 的集合类的时候，如果发生ConcurrentModificationException，优先考虑 fail-fast 有关的情况，实际上这可能并没有真的发生并发，只是 Iterator 使用了 fail-fast 的保护机制，只要他发现有某一次修改是未经过自己进行的，那么就会抛出异常。Iterator 发现集合中的元素被修改是通过一个全局变量 modCount 发现的。我们在调用集合的 remove/add 方法的时候 modCount 都会加一，而在使用 Iterator 进行遍历的时候，它首先会保存一份 modCount， 即：expectedModCount = modCount，然后在每一次遍历的时候就会去比较 expectedModCountt 和 modCount 是否相等，不相等就会触发 fast-fail 机制：抛出 ConcurrentModificationExcetion

## LinkedList

### LinkedList 的结构

```java
public class LinkedList<E> extends AbstractSequentialList<E> implements List<E>, Deque<E>, Cloneable, Serializable {
    transient int size;
    transient LinkedList.Node<E> first;
    transient LinkedList.Node<E> last;
}
```

LinkedList 由一个头节点和一个尾节点组成，分别指向链表的头部和尾部，还有一个 size 表示当前容器存储的元素个数

Node 的结构

```java
private static class Node<E> {
    E item;
    Node<E> next;
    Node<E> prev;

    Node(Node<E> prev, E element, Node<E> next) {
        this.item = element;
        this.next = next;
        this.prev = prev;
    }
}
```

可以看到 LinkedList 的每个节点都有其前驱和后继指针，典型的双向链表。并且 Node 只有一个构造方法。

### LinkedList查询方法

按照下标获取某一个节点：get 方法，获取第 index 个节点。

```java
public E get(int index) {
    checkElementIndex(index);
    return node(index).item;
}
```

node(index) 方法是怎么实现的呢？判断 index 是更靠近头部还是尾部，靠近哪段从哪段遍历获取值。

```java
Node<E> node(int index) {
    // assert isElementIndex(index);
    //判断index更靠近头部还是尾部
    if (index < (size >> 1)) {
        Node<E> x = first;
        for (int i = 0; i < index; i++)
            x = x.next;
        return x;
    } else {
        Node<E> x = last;
        for (int i = size - 1; i > index; i--)
            x = x.prev;
        return x;
    }
}
```

### LinkedList 的修改方法

```java
public boolean add(E e) {
    linkLast(e);
    return true;
}
```

可以看到，默认是采用尾插法进行插入

## Vector

和 ArrayList 一样，Vector 也是 List 接口的一个实现类。其中 List 接口主要实现类有 ArrayLIst，LinkedList，Vector，Stack，其中后两者用的特别少。

### vector组成

和ArrayList基本一样。

```java
//存放元素的数组
protected Object[] elementData;
//有效元素数量，小于等于数组长度
protected int elementCount;
//容量增加量，和扩容相关
protected int capacityIncrement;
```

### vector 线程安全性

vector 是线程安全的，synchronized 修饰的操作方法。

### vector 扩容

```java
protected Object[] elementData;
protected int elementCount;
protected int capacityIncrement;
private static final long serialVersionUID = -2767605614048989439L;
private static final int MAX_ARRAY_SIZE = 2147483639;

public Vector(int var1, int var2) {
    if (var1 < 0) {
        throw new IllegalArgumentException("Illegal Capacity: " + var1);
    } else {
        this.elementData = new Object[var1];
        this.capacityIncrement = var2;
    }
}

private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    //扩容大小
    int newCapacity = oldCapacity + ((capacityIncrement > 0) ?
                                     capacityIncrement : oldCapacity);
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    elementData = Arrays.copyOf(elementData, newCapacity);
}
```

看源码可知，当创建 Vector 的时候，如果没有指定 capacityIncrement 时，一次扩容数组大小变成原来的两倍，否则每次增加 capacityIncrement。

## PriorityQueue

### PriorityQueue 的组成

```Java
/**
 * 默认容量大小，数组大小
 */
private static final int DEFAULT_INITIAL_CAPACITY = 11;

/**
 * 存放元素的数组
 */
transient Object[] queue; // non-private to simplify nested class access

/**
 * 队列中存放了多少元素
 */
private int size = 0;

/**
 * 自定义的比较规则，有该规则时优先使用，否则使用元素实现的 Comparable 接口方法。
 */
private final Comparator<? super E> comparator;

/**
 * 队列修改次数，每次存取都算一次修改
 */
transient int modCount = 0; // non-private to simplify nested class access
```

可以看到 PriorityQueue 的组成很简单，主要记住一个**存放元素的数组**，和一个 **Comparator 比较器**即可。

### PriorityQueue 操作的方法

### 添加元素

#### offer 方法

```java
public boolean offer(E e) {
    if (e == null)
        throw new NullPointerException();
    modCount++;
    int i = size;
    if (i >= queue.length)
        grow(i + 1);
    size = i + 1;
    //i=size，当queue为空的时候
    if (i == 0)
        queue[0] = e;
    else
        siftUp(i, e);
    return true;
}
```

可以看到，当 queue 为空的时候，会直接将元素放在 queue 的第一个位置。否则就调用 siftUp(i, e) 方法完成插入工作，第一个参数是没扩容之前的数组大小，即表示前 i - 1 个位置都是排好序的，现在要插入第 i 个元素

#### siftUp 方法

```java
private void siftUp(int k, E x) {
    if (comparator != null)
        siftUpUsingComparator(k, x);
    else
        siftUpComparable(k, x);
}
```

从上面的方法中可以看出，优先使用自定义的比较器：Comparator, 如果没有就使用添加的元素实现的 Comparable 接口中的 compareTo 方法。

```java
private void siftUpComparable(int k, E x) {
    Comparable<? super E> key = (Comparable<? super E>) x;
    while (k > 0) {
      //为什么-1， 思考数组位置0，1，2。0是1和2的父节点
        int parent = (k - 1) >>> 1;
        //父节点
        Object e = queue[parent];
        //当传入的新节点大于父节点则不做处理，否则二者交换
        if (key.compareTo((E) e) >= 0)
            break;
        queue[k] = e;
        k = parent;
    }
    queue[k] = key;
}
```

可以看到，当 PriorityQueue 不为空时插入一个新元素，会对其新元素进行堆排序处理。这样每次进来都会对该元素进行堆排序运算，这样也就保证了 Queue 中第一个元素永远是最小的（默认规则排序）。

siftUpUsingComparator 方法的比较和 SiftUpComparable 方法一样，只不过它使用的是自定义的 Comparator 中的 compare 方法进行比较 

```java
private void siftUpUsingComparator(int k, E x) {
    while (k > 0) {
        int parent = (k - 1) >>> 1;
        Object e = queue[parent];
        if (comparator.compare(x, (E) e) >= 0)
            break;
        queue[k] = e;
        k = parent;
    }
    queue[k] = x;
}
```

### 取出元素

#### poll()方法

```java
public E poll() {
    if (size == 0)
        return null;
    int s = --size;
    modCount++;
    E result = (E) queue[0];
    //s = --size,即原来数组的最后一个元素
    E x = (E) queue[s];
    queue[s] = null;
    if (s != 0)
        siftDown(0, x);
    return result;
}
```

从上面可以看出，取出元素使用的方法是 siftDown。**传入的参数为索引 0 和队列中的最后一个元素**

```java
private void siftDown(int k, E x) {
    if (comparator != null)
        siftDownUsingComparator(k, x);
    else
        siftDownComparable(k, x);
}
```

```java
private void siftDownComparable(int k, E x) {
    Comparable<? super E> key = (Comparable<? super E>)x;
    int half = size >>> 1; // loop while a non-leaf
    while (k < half) {
        int child = (k << 1) + 1; // assume left child is least
        Object c = queue[child];
        int right = child + 1;
        if (right < size &&
          //c 和 right 是 parent 的两个子节点，找出小的那个成为新的 c。
            ((Comparable<? super E>) c).compareTo((E) queue[right]) > 0)
            c = queue[child = right];
        if (key.compareTo((E) c) <= 0)
            break;
        //小的变成了新的父节点 
        queue[k] = c;
        k = child;
    }
    queue[k] = key;
}
```

因为**索引0位置取出**了，找**索引 0 的子节点比它小的作为新的父节点并在循环内递归**

## ArrayDeque

ArrayDeque 是 Java 中基于数组实现的双端队列。在 Java 中 Deque 的实现有 LinkedList 和ArrayDeque。正如他俩的名字就标志了它们的不同，LinkedList 是基于双向链表实现的，而 ArrayDeque 是基于数组实现的。

### ArrayDeque 的组成

```java
//具体存放元素的数组，数组大小一定是2的幂次方
transient Object[] elements; // non-private to 
//队列头索引
transient int head;
//队列尾索引
transient int tail;
//默认的最小初始化容量，即传入的容量小于 8 容量为 8，而默认容量是 16
private static final int MIN_INITIAL_CAPACITY = 8;
```

### 构造方法

```java
public ArrayDeque() {
    elements = new Object[16];
}

public ArrayDeque(int numElements) {
    allocateElements(numElements);
}
```

如果没有传入参数：默认容量 16。如果在创建 ArrayQueue 的时候，传递了容量，但是小于等于 8 的话，最小为 8，否则为大于指定容量的最小的 2 的 n 幂。比如传入 9， 那么创建出的容量就为 16

### 数组 elements 的容量

```java
private void allocateElements(int numElements) {
    int initialCapacity = MIN_INITIAL_CAPACITY;
    // Find the best power of two to hold elements.
    // Tests "<=" because arrays aren't kept full.
    if (numElements >= initialCapacity) {
        initialCapacity = numElements;
        // 接下来的以为运算保证容量的大小为 2 的 n 次幂，最小的容量为 8
        initialCapacity |= (initialCapacity >>>  1);
        initialCapacity |= (initialCapacity >>>  2);
        initialCapacity |= (initialCapacity >>>  4);
        initialCapacity |= (initialCapacity >>>  8);
        initialCapacity |= (initialCapacity >>> 16);
        initialCapacity++;
       

        if (initialCapacity < 0)   // Too many elements, must back off
            initialCapacity >>>= 1;// Good luck allocating 2 ^ 30 elements
    }
    elements = new Object[initialCapacity];
}


private void doubleCapacity() {
    assert head == tail;
    int p = head;
    int n = elements.length;
    int r = n - p; // number of elements to the right of p
    int newCapacity = n << 1;
    if (newCapacity < 0)
        throw new IllegalStateException("Sorry, deque too big");
    Object[] a = new Object[newCapacity];
    System.arraycopy(elements, p, a, 0, r);
    System.arraycopy(elements, 0, a, r, p);
    elements = a;
    head = 0;
    tail = n; // tail 指针指向新数组当前数组的中间
}

```

### ArrayQueue 的实现机制

ArrayQueue 添加元素的机制是：addFirst 从最后一个位置开始添加元素，指针从右往左走。addLast 从数组中第一个位置开始添加元素，指针从左往右走。head 指针和 tail 指针相向而行，当 head 和 tail 指针相等时，进行扩容，扩容之后的容量为: 当前容量 * 2

```java
public void addFirst(E e) {
    if (e == null)
        throw new NullPointerException();
    // -1 的补码：11111 容量为 16, 16 - 1 = 15
    //  11111
    //& 01111
    //= 01111 ==> 15
    elements[head = (head - 1) & (elements.length - 1)] = e;
    if (head == tail)
        doubleCapacity();
}

public void addLast(E e) {
    if (e == null)
        throw new NullPointerException();
    elements[tail] = e;
    //  010001
    //& 001111
    //  000001 ==> 1
    
    if ( (tail = (tail + 1) & (elements.length - 1)) == head)
        doubleCapacity();
}
```

移出的操作则刚好相反。

## Set

如果说 List 对集合加了有序性的话，那么 Set 就是对集合加上了唯一性。

## HashSet

```java
private transient HashMap<E,Object> map;

// 存放键值对的使用，value 里存放的是 PRESENT
private static final Object PRESENT = new Object();
```

可以看到 HashSet 内部其实是一个 HashMap

### HashSet是如何保证不重复的呢？

```java
public boolean add(E e) {
    return map.put(e, PRESENT) == null;
}
```

可以看法 add 方法将添加的值作为 HashMap 的 key。而 HashMap 的 key 是不允许重复的，但是 value 是可以重复的。map 的 put方法新增一个原来不存在的值会返回 null，如果原来存在的话会返回原来存在的值

## LinkedHashSet

- LinkedHashSet 是 HashSet 的子类，底层使用了 LinkedHashMap，在 HashSet 的哈希表数据结构基础之上，增加了一个双向链表用来记录元素添加的顺序，能按照添加顺序遍历输出。需要频繁遍历的话效率可能高于HashSet

- 具有可预测的迭代次序的Set接口的哈希表(数组+链表/红黑树)和链表(用来记录元素的存储顺序，可以保证元素有序)的实现
- 有序、不允许重复
- 由于需要额外维护链表，性能可能略低于HashSet
- 该类提供了所有可选的Set操作，并允许null元素
- 请注意，此实现不同步
- 在HshSet底层存储结构的基础上，额外提供了一对指针记录Node元素的上一个元素和下一个元素，可以按照元素添加的顺序实现遍历
- 对于频繁的遍历，效率高于HashSet

## HashMap

### HashMap存储的数据

Map 接口中有一个 Entry 接口，在 HashMap 中对其进行了实现，Entry 的实现是 HashMap 存放的数据的类型。其中 Entry 在 HashMap 的实现是 Node，Node 是一个单链表的结构，TreeNode 是其子类，是一个红黑树的类型

```java
//是hashMap的最小容量16，容量就是数组的大小也就是变量，transient Node<K,V>[] table。
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

//最大数量，该数组最大值为2^31一次方。
static final int MAXIMUM_CAPACITY = 1 << 30;

//默认的加载因子，如果构造的时候不传则为0.75
static final float DEFAULT_LOAD_FACTOR = 0.75f;

//一个位置里存放的节点数转化成树的阈值，也就是8，比如数组里有一个node，这个 
// node链表的长度达到该值才会转化为红黑树。
static final int TREEIFY_THRESHOLD = 8;

//当一个反树化的阈值，当这个node长度减少到该值就会从树转化成链表
static final int UNTREEIFY_THRESHOLD = 6;

//满足节点变成树的另一个条件，就是存放 node 的数组长度要达到64
static final int MIN_TREEIFY_CAPACITY = 64;

//具体存放数据的数组，实现了 Map.Entry<K,V> 接口
transient Node<K,V>[] table;

//entrySet，一个存放k-v缓冲区
transient Set<Map.Entry<K,V>> entrySet;

//size是指hashMap中存放了多少个键值对
transient int size;

//对map的修改次数
transient int modCount;

//加载因子
final float loadFactor;

//哈希表内元素数量的阈值，当哈希表内元素数量超过阈值时，会发生扩容resize()。
int threshold; // (size / loadFactor) > threshold 就扩容， 且 threshold 总是为 2 的 n 次方。


static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;
}
```

```java
public class Objects{
    public static boolean equals(Object a, Object b) {
    	return (a == b) || (a != null && a.equals(b));
	}
}

```

### HashMap的构造方法

```java
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                           initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                           loadFactor);
    this.loadFactor = loadFactor;
    this.threshold = tableSizeFor(initialCapacity);
}

public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}

public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}

public HashMap(Map<? extends K, ? extends V> m) {
    this.loadFactor = DEFAULT_LOAD_FACTOR;
    putMapEntries(m, false);
}
```

刚刚创建 HashMap 的是否不会分配容量容量，在放入第一个元素的时候才会分配默认容量 16。

tableSizeFor 方法保证了数组的大小一定是 2 的幂次方

```java
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

该方法将一个二进制数第一位 1 后边的数字全部变成 1，然后再加 1，这样这个二进制数就一定是 100… 这样的形式, 会保证 table 的容量一定是大于等于 cap 的最小的 2 的 n 次幂，例如传入 9， 则返回 16。

### put 方法添加元素

```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    Node<K,V>[] tab;
    Node<K,V> p;
    int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    //当hash到的位置，该位置为null的时候，存放一个新node放入 
    // 这儿p赋值成了table该位置的node值
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        Node<K,V> e; K k;
        //该位置第一个就是查找到的值，将p赋给e
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        //如果是红黑树，调用红黑树的putTreeVal方法 
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
          // 使用尾插法是为了在多线程中避免环的出现，虽然尾插法可以避免环的出现，但是还是会出线数据覆盖的情况
          //是链表，遍历，注意e = p.next这个一直将下一节点赋值给e，直到尾部，注意开头是++binCount
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    //当链表长度大于等于7，插入第8位，树化
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            //这是一个空实现的函数，用作LinkedHashMap重写使用。
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    if (++size > threshold)
        resize();
    //这是一个空实现的函数，用作LinkedHashMap重写使用。
    afterNodeInsertion(evict);
    return null;
}
```

```java
final Node<K,V>[] resize() {
        //oldTab 为当前表的哈希桶
        Node<K,V>[] oldTab = table;
        //当前哈希桶的容量 length
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        //当前的阈值
        int oldThr = threshold;
        //初始化新的容量和阈值为0
        int newCap, newThr = 0;
        //如果当前容量大于0
        if (oldCap > 0) {
            //如果当前容量已经到达上限
            if (oldCap >= MAXIMUM_CAPACITY) {
                //则设置阈值是2的31次方-1
                threshold = Integer.MAX_VALUE;
                //同时返回当前的哈希桶，不再扩容
                return oldTab;
            }//否则新的容量为旧的容量的两倍。 
            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                     oldCap >= DEFAULT_INITIAL_CAPACITY)//如果旧的容量大于等于默认初始容量16
                //那么新的阈值也等于旧的阈值的两倍
                newThr = oldThr << 1; // double threshold
        }//如果当前表是空的，但是有阈值。代表是初始化时指定了容量、阈值的情况
        else if (oldThr > 0) // initial capacity was placed in threshold
            newCap = oldThr;//那么新表的容量就等于旧的阈值
        else {}//如果当前表是空的，而且也没有阈值。代表是初始化时没有任何容量/阈值参数的情况               // zero initial threshold signifies using defaults
            newCap = DEFAULT_INITIAL_CAPACITY;//此时新表的容量为默认的容量 16
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);//新的阈值为默认容量16 * 默认加载因子0.75f = 12
        }
        if (newThr == 0) {//如果新的阈值是0，对应的是  当前表是空的，但是有阈值的情况
            float ft = (float)newCap * loadFactor;//根据新表容量 和 加载因子 求出新的阈值
            //进行越界修复
            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        //更新阈值 
        threshold = newThr;
        @SuppressWarnings({"rawtypes","unchecked"})
        //根据新的容量 构建新的哈希桶
            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
        //更新哈希桶引用
        table = newTab;
        //如果以前的哈希桶中有元素
        //下面开始将当前哈希桶中的所有节点转移到新的哈希桶中
        if (oldTab != null) {
            //遍历老的哈希桶
            for (int j = 0; j < oldCap; ++j) {
                //取出当前的节点 e
                Node<K,V> e;
                //如果当前桶中有元素,则将链表赋值给e
                if ((e = oldTab[j]) != null) {
                    //将原哈希桶置空以便GC
                    oldTab[j] = null;
                    //如果当前链表中就一个元素，（没有发生哈希碰撞）
                    if (e.next == null)
                        //直接将这个元素放置在新的哈希桶里。
                        //注意这里取下标 是用 哈希值 与 桶的长度-1 。 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。但是效率更高
                        newTab[e.hash & (newCap - 1)] = e;
                        //如果发生过哈希碰撞 ,而且是节点数超过8个，转化成了红黑树（暂且不谈 避免过于复杂， 后续专门研究一下红黑树）
                    else if (e instanceof TreeNode)
                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                    //如果发生过哈希碰撞，节点数小于8个。则要根据链表上每个节点的哈希值，依次放入新哈希桶对应下标位置。
                    else { // preserve order
                        //因为扩容是容量翻倍，所以原链表上的每个节点，现在可能存放在原来的下标，即low位， 或者扩容后的下标，即high位。 high位=  low位+原哈希桶容量
                        //低位链表的头结点、尾节点
                        Node<K,V> loHead = null, loTail = null;
                        //高位链表的头节点、尾节点
                        Node<K,V> hiHead = null, hiTail = null;
                        Node<K,V> next;//临时节点 存放e的下一个节点
                        do {
                            next = e.next;
                            //这里又是一个利用位运算 代替常规运算的高效点： 利用哈希值 与 旧的容量，可以得到哈希值去模后，是大于等于oldCap还是小于oldCap，等于0代表小于oldCap，应该存放在低位，否则存放在高位
                            if ((e.hash & oldCap) == 0) {
                                //给头尾节点指针赋值
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }//高位也是相同的逻辑
                            else {
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }//循环直到链表结束
                        } while ((e = next) != null);
                        //将低位链表存放在原index处，
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        //将高位链表存放在新index处
                        if (hiTail != null) {
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }
```

### 获取元素：get()

```java
/*  扰动函数就是为了解决hash碰撞的。它会综合hash 值高位和低位的特征，并存放在低位，
 *	因此在与运算时，相当于高低位一起参与了运算，以减少hash碰撞的概率
 */
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab;
    Node<K,V> first, e;
    int n; K k;
    //先判断表不为空
    if ((tab = table) != null && (n = tab.length) > 0 &&
        //这一行是找到要查询的 Key 在 table 中的位置，table 是存放 HashMap 中每一个 Node 的数组。
        (first = tab[(n - 1) & hash]) != null) {
        //Node 可能是一个链表或者树，先判断根节点是否是要查询的 key,就是根节点，方便后续遍历 Node 写法并且
        //对于只有根节点的Node直接判断
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        //有子节点
        if ((e = first.next) != null) {
            //红黑树查找
            if (first instanceof TreeNode) // TreeNode 是 Node 的子类
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do {
                //链表查找
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            }
            //遍历链表，当链表后续为null则推出循环
            while ((e = e.next) != null);
        }
    }
    return null;
}
```

### 与 `HashTable` 的区别

- 与之相比`HashTable`是线程安全的，且不允许key、value是null。
- `HashTable`默认容量是 11。
- `HashTable` 是直接使用 key 的hashCode(`key.hashCode()`)作为hash值，不像`HashMap`内部使用`static final int hash(Object key) `扰动函数对 key 的 hashCode 进行扰动后作为 hash 值。
- `HashTable` 取哈希桶下标是直接用模运算 %.（因为其默认容量也不是2的n次方。所以也无法用位运算替代模运算）
- 扩容时，新容量是原来的2倍+1。`int newCapacity = (oldCapacity << 1) + 1;`
- `Hashtable` 是 `Dictionary` 的子类同时也实现了 `Map` 接口，`HashMap `是 `Map` 接口的一个实现类；

## HashTable

和 HashMap 不同，HashTable 的实现方式完全不同，这点从二者的类继承关系就可以看出端倪来，HashTable  和 HashMap 虽然都实现了Map接口，但是 HashTable 继承了 Dictionary 抽象类，而 HashMap 继承了AbstractMap 抽象类。

Dictionary 类中有这样一行注释，当 key 为 null 时会抛出空指针 NullPointerException,这也说明了HashTabel 是不允许 Key 为 null 的。

### HashTable 的组成

```java
//真正存放数据的数组
private transient Entry<?,?>[] table;

private transient int count;

private int threshold;

private float loadFactor;

```

HashTable 中的元素存在 Entry[] table 中，是一个Entry数组，Entry 是存放的节点，每一个 Entry 是一个链表。

### HashTable 中的 Entry

```java
final int hash;
final K key;
V value;
Entry<K,V> next;
```

知道 Entry 是一个单链表即可，和 HashMap 中的 Node 结构相同，但是 HashMap 中还有 Node 的子类TreeNode。

### put 方法

```java
public synchronized V put(K key, V value) {
    // Make sure the value is not null
    if (value == null) {
        throw new NullPointerException();
    }

    // Makes sure the key is not already in the hashtable.
    Entry<?,?> tab[] = table;
    int hash = key.hashCode();
    //在数组中的位置 0x7fffffff 是31位二进制1 
    int index = (hash & 0x7FFFFFFF) % tab.length;
    @SuppressWarnings("unchecked")
    Entry<K,V> entry = (Entry<K,V>)tab[index];
    for(; entry != null ; entry = entry.next) {
      //如果遍历链表找到了则替换旧值并返回
        if ((entry.hash == hash) && entry.key.equals(key)) {
            V old = entry.value;
            entry.value = value;
            return old;
        }
    }

    addEntry(hash, key, value, index);
    return null;
}
```

本质上就是先 hash 求索引，遍历该索引 Entry 链表，如果找到 hash 值和 key 都和 put 的 key 一样的时候就替换旧值，否则使用 addEntry 方法添加新值进入 table，因为添加新元素就涉及到修改元素大小，还可能需要扩容等，具体看下边的 addEntry 方法可知。

```java
private void addEntry(int hash, K key, V value, int index) {
    Entry<?,?> tab[] = table;
    //如果扩容需要重新计算hash，所以index和table都会被修改
    if (count >= threshold) {
        // Rehash the table if the threshold is exceeded
        rehash();

        tab = table;
        hash = key.hashCode();
        index = (hash & 0x7FFFFFFF) % tab.length;
    }
    // Creates the new entry.
    @SuppressWarnings("unchecked")
    Entry<K,V> e = (Entry<K,V>) tab[index];
    //插入新元素
    tab[index] = new Entry<>(hash, key, value, e);
    count++;
    modCount++;
}
```

```java
tab[index] = new Entry<>(hash, key, value, e);
```

这行代码是真正插入新元素的方法，采用头插法，**单链表一般都用头插法**（快）。

### get方法

```java
@SuppressWarnings("unchecked")
public synchronized V get(Object key) {
    Entry<?,?> tab[] = table;
    int hash = key.hashCode();
    int index = (hash & 0x7FFFFFFF) % tab.length;
    for (Entry<?,?> e = tab[index] ; e != null ; e = e.next) {
        if ((e.hash == hash) && e.key.equals(key)) {
            return (V)e.value;
        }
    }
    return null;
}
```

get 方法就简单很多就是 hash，找到索引，遍历链表找到对应的 value，没有则返回 null。相比诸君都已经看到，HashTable 中方法是用 synchronized 修饰的，所以其操作是线程安全的，但是效率会受影响。

## LinkedHashMap

LinkedHashMap 继承自 HashMap，在 HashMap 基础上，通过维护一条双向链表，解决了 HashMap 不能随时保持遍历顺序和插入顺序一致的问题。除此之外，LinkedHashMap 对访问顺序也提供了相关支持。在一些场景下，该特性很有用，比如缓存。在实现上，LinkedHashMap 很多方法直接继承自 HashMap，仅为维护双向链表覆写了部分方法。

```java
transient LinkedHashMap.Entry<K,V> head;
transient LinkedHashMap.Entry<K,V> tail;

static class Entry<K,V> extends HashMap.Node<K,V> {
    Entry<K,V> before, after;
    Entry(int hash, K key, V value, Node<K,V> next) {
        super(hash, key, value, next);
    }
}
```

LinkedHashMap 存储数据的节点在 HashMap 存储数据的结点 Node 上增加了两个指针 before 和 after，分别指向它的前驱和后继。每当有新键值对节点插入，新节点最终会接在 tail 引用指向的节点后面,而 tail 引用则会移动到新的节点上，这样一个双向链表就建立起来了。

HashMap 的内部类 TreeNode 没有继承它的一个内部类 Node，却继承自 Node 的子类 LinkedHashMap 内部类 Entry。LinkedHashMap 内部类 Entry 继承自 HashMap 内部类 Node，并新增了两个引用，分别是 before 和 after。这两个引用的用途不难理解，也就是用于维护双向链表。同时，TreeNode 继承 LinkedHashMap 的内部类 Entry 后，就具备了和其他 Entry 一起组成链表的能力。

但是这里需要大家考虑一个问题。当我们使用 HashMap 时，TreeNode 并不需要具备组成链表能力。如果继承 LinkedHashMap 内部类 Entry ，TreeNode 就多了两个用不到的引用，这样做不是会浪费空间吗？简单说明一下这个问题（水平有限，不保证完全正确），这里这么做确实会浪费空间，但与 TreeNode 通过继承获取的组成链表的能力相比，这点浪费是值得的。在 HashMap 的设计思路注释中，有这样一段话：

> Because TreeNodes are about twice the size of regular nodes, we
> use them only when bins contain enough nodes to warrant use
> (see TREEIFY_THRESHOLD). And when they become too small (due to
> removal or resizing) they are converted back to plain bins. In
> usages with well-distributed user hashCodes, tree bins are
> rarely used.

大致的意思是 TreeNode 对象的大小约是普通 Node 对象的2倍，我们仅在桶（bin）中包含足够多的节点时再使用。当桶中的节点数量变少时（取决于删除和扩容），TreeNode 会被转成 Node。当用户实现的 hashCode 方法具有良好分布性时，树类型的桶将会很少被使用。

通过上面的注释，我们可以了解到。一般情况下，只要 hashCode 的实现不糟糕，Node 组成的链表很少会被转成由 TreeNode 组成的红黑树。也就是说 TreeNode 使用的并不多，浪费那点空间是可接受的。假如 TreeNode 机制继承自 Node 类，那么它要想具备组成链表的能力，就需要 Node 去继承 LinkedHashMap 的内部类 Entry。这个时候就得不偿失了，浪费很多空间去获取不一定用得到的能力。

### 双向链表建立的过程

Map 类型的集合类是通过 put(K,V) 方法插入键值对，LinkedHashMap 本身并没有覆写父类的 put 方法，而是直接使用了父类的实现。但在 HashMap 中，put 方法插入的是 HashMap 内部类 Node 类型的节点，该类型的节点并不具备与 LinkedHashMap 内部类 Entry 及其子类型节点组成链表的能力。那么，LinkedHashMap 是怎样建立链表的呢？

```java
// HashMap 中实现
Node<K,V> newNode(int hash, K key, V value, Node<K,V> next) {
    return new Node<>(hash, key, value, next);
}

// LinkedHashMap 中覆写
Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {
    LinkedHashMap.Entry<K,V> p =
        new LinkedHashMap.Entry<K,V>(hash, key, value, e);
    // 将 Entry 接在双向链表的尾部
    linkNodeLast(p);
    return p;
}

// LinkedHashMap 中实现
private void linkNodeLast(LinkedHashMap.Entry<K,V> p) {
    LinkedHashMap.Entry<K,V> last = tail;
    tail = p;
    // last 为 null，表明链表还未建立
    if (last == null)
        head = p;
    else {
        // 将新节点 p 接在链表尾部
        p.before = last;
        last.after = p;
    }
}

// LinkedHashMap 中覆写
void afterNodeRemoval(Node<K,V> e) { // unlink
    LinkedHashMap.Entry<K,V> p =
        (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
    // 将 p 节点的前驱后后继引用置空
    p.before = p.after = null;
    // b 为 null，表明 p 是头节点
    if (b == null)
        head = a;
    else
        b.after = a;
    // a 为 null，表明 p 是尾节点
    if (a == null)
        tail = b;
    else
        a.before = b;
}
```

在插入结点的时候，通过重写 NewNode 方法实现双向链表结点的创建。在通过 linkNodeLast 方法将链表链接起来,从而实现双向链表的建立。

### 访问顺序的维护过程

前面说了插入顺序的实现，本节来讲讲访问顺序。默认情况下，LinkedHashMap 是按插入顺序维护链表。不过我们可以在初始化 LinkedHashMap，指定 accessOrder 参数为 true，即可让它按访问顺序维护链表。访问顺序的原理上并不复杂，当我们调用`get/getOrDefault/replace`等方法时，只需要将这些方法访问的节点移动到链表的尾部即可。相应的源码如下：

```java
// LinkedHashMap 中覆写
public V get(Object key) {
    Node<K,V> e;
    if ((e = getNode(hash(key), key)) == null)
        return null;
    // 如果 accessOrder 为 true，则调用 afterNodeAccess 将被访问节点移动到链表最后
    if (accessOrder)
        afterNodeAccess(e);
    return e.value;
}

// LinkedHashMap 中覆写
void afterNodeAccess(Node<K,V> e) { // move node to last
    LinkedHashMap.Entry<K,V> last;
    if (accessOrder && (last = tail) != e) {
        LinkedHashMap.Entry<K,V> p =
            (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
        p.after = null;
        // 如果 b 为 null，表明 p 为头节点
        if (b == null)
            head = a;
        else
            b.after = a;

        if (a != null)
            a.before = b;
        /*
         * 这里存疑，父条件分支已经确保节点 e 不会是尾节点，
         * 那么 e.after 必然不会为 null，不知道 else 分支有什么作用
         */
        else
            last = b;

        if (last == null)
            head = p;
        else {
            // 将 p 接在链表的最后
            p.before = last;
            last.after = p;
        }
        tail = p;
        ++modCount;
    }
}
```

### 基于 LinkedHashMap 实现缓存

前面介绍了 LinkedHashMap 是如何维护插入和访问顺序的，大家对 LinkedHashMap 的原理应该有了一定的认识。本节我们来写一些代码实践一下，这里通过继承 LinkedHashMap 实现了一个简单的 LRU(最近最少被使用) 策略的缓存。在写代码之前，先介绍一下前置知识。

在3.1节分析链表建立过程时，我故意忽略了部分源码分析。本节就把忽略的部分补上，先看源码吧：

```java
void afterNodeInsertion(boolean evict) { // possibly remove eldest
    LinkedHashMap.Entry<K,V> first;
    // 根据条件判断是否移除最近最少被访问的节点
    if (evict && (first = head) != null && removeEldestEntry(first)) {
        K key = first.key;
        removeNode(hash(key), key, null, false, true);
    }
}

// 移除最近最少被访问条件之一，通过覆盖此方法可实现不同策略的缓存
protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
    return false;
}
```

上面的源码的核心逻辑在一般情况下都不会被执行，所以之前并没有进行分析。上面的代码做的事情比较简单，就是通过一些条件，判断是否移除最近最少被访问的节点。看到这里，大家应该知道上面两个方法的用途了。当我们基于 LinkedHashMap 实现缓存时，通过覆写`removeEldestEntry`方法可以实现自定义策略的 LRU 缓存。比如我们可以根据节点数量判断是否移除最近最少被访问的节点，或者根据节点的存活时间判断是否移除该节点等。本节所实现的缓存是基于判断节点数量是否超限的策略。在构造缓存对象时，传入最大节点数。当插入的节点数超过最大节点数时，移除最近最少被访问的节点。实现代码如下：

```java
public class SimpleCache<K, V> extends LinkedHashMap<K, V> {

    private static final int MAX_NODE_NUM = 100;

    private int limit;

    public SimpleCache() {
        this(MAX_NODE_NUM);
    }

    public SimpleCache(int limit) {
        super(limit, 0.75f, true);
        this.limit = limit;
    }

    public V save(K key, V val) {
        return put(key, val);
    }

    public V getOne(K key) {
        return get(key);
    }

    public boolean exists(K key) {
        return containsKey(key);
    }

    /**
     * 判断节点数是否超限
     * @param eldest
     * @return 超限返回 true，否则返回 false
     */
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        return size() > limit;
    }
}
```

测试代码如下：

```java
public class SimpleCacheTest {

    @Test
    public void test() throws Exception {
        SimpleCache<Integer, Integer> cache = new SimpleCache<>(3);

        for (int i = 0; i < 10; i++) {
            cache.save(i, i * i);
        }

        System.out.println("插入10个键值对后，缓存内容：");
        System.out.println(cache + "\n");

        System.out.println("访问键值为7的节点后，缓存内容：");
        cache.getOne(7);
        System.out.println(cache + "\n");

        System.out.println("插入键值为1的键值对后，缓存内容：");
        cache.save(1, 1);
        System.out.println(cache);
    }
}
```

### 总结

本文从 LinkedHashMap 维护双向链表的角度对 LinkedHashMap 的源码进行了分析，并在文章的结尾基于 LinkedHashMap 实现了一个简单的 Cache。在日常开发中，LinkedHashMap 的使用频率虽不及 HashMap，但它也个重要的实现。在 Java 集合框架中，HashMap、LinkedHashMap 和 TreeMap 三个映射类基于不同的数据结构，并实现了不同的功能。HashMap 底层基于拉链式的散列结构，并在 JDK 1.8 中引入红黑树优化过长链表的问题。基于这样结构，HashMap 可提供高效的增删改查操作。LinkedHashMap 在其之上，通过维护一条双向链表，实现了散列数据结构的有序遍历。TreeMap 底层基于红黑树实现，利用红黑树的性质，实现了键值对排序功能。

## TreeMap

### 简介

`TreeMap`最早出现在`JDK 1.2`中，是 Java 集合框架中比较重要一个的实现。TreeMap 底层基于`红黑树`实现，可保证在`log(n)`时间复杂度内完成 containsKey、get、put 和 remove 操作，效率很高。另一方面，由于 TreeMap 基于红黑树实现，这为 TreeMap 保持键的有序性打下了基础。总的来说，TreeMap 的核心是红黑树，其很多方法也是对红黑树增删查基础操作的一个包装。所以只要弄懂了红黑树，TreeMap 就没什么秘密了。

![TreeMap继承图](/home/autmaple/Documents/Notes/Attachment/TreeMap继承图.png)

- TreeMap实现了 NavigableMap 接口，而 NavigableMap 接口继承着 SortedMap 接口，致使我们的**TreeMap是有序的**！

- TreeMap底层是红黑树，它方法的时间复杂度都不会太高:log(n)

- 使用 Comparator 或者 Comparable 来比较 key 是否相等与排序的问题

- 由于底层是红黑树，那么时间复杂度可以保证为log(n)

- key 不能为 null，为 null 为抛出 NullPointException 的

- 想要自定义比较，在构造方法中传入 Comparator 对象，否则使用 key 的自然排序来进行比较

- TreeMap 非同步的，想要同步可以使用 Collections 来进行封装
